# -*- coding: utf-8 -*-
"""cc-credit-card.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VB9_An-j66hJLefQyL-bJvjxdbMvwJrs
"""

#Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#For ignoring warning
import warnings
warnings.filterwarnings("ignore")

df=pd.read_csv('/content/drive/MyDrive/preparation examen/03 dec 2025 /credit_card_fraud_dataset.csv')
df

df.shape



"""# Task
Detect credit card fraud using the provided `credit_card_fraud_dataset.csv` by defining the problem (classification) and creating a data dictionary for the dataset.

## Définition de la problématique et dictionnaire des données

### Subtask:
Définir précisément la problématique (classification binaire/multi-classe, régression, clustering) et décrire les métadonnées : taille, types de variables, signification des features et identification de la variable cible.

### Problématique

Le problème posé est une tâche de **classification binaire**. L'objectif est de prédire si une transaction par carte de crédit est frauduleuse (classe 1) ou non frauduleuse (classe 0), en se basant sur les caractéristiques de la transaction. La variable cible est 'IsFraud'.

**Reasoning**:
The next instruction is to determine the shape (number of rows and columns) of the DataFrame `df`.
"""

print(f"DataFrame shape: {df.shape}")

"""**Reasoning**:
The next instruction is to identify the data type of each column in the DataFrame `df` to understand the nature of the variables.


"""

df.info()

"""### Data Dictionary

| Feature Name    | Data Type | Description                                                      | Target Variable |
| :-------------- | :-------- | :--------------------------------------------------------------- | :-------------- |
| `TransactionID`   | int64     | Unique identifier for each transaction.                          | No              |
| `TransactionDate` | object    | Date and time when the transaction occurred.                     | No              |
| `Amount`          | float64   | The monetary value of the transaction.                           | No              |
| `MerchantID`      | int64     | Identifier for the merchant where the transaction took place.    | No              |
| `TransactionType` | object    | Type of transaction (e.g., 'purchase', 'refund').                | No              |
| `Location`        | object    | Geographical location where the transaction occurred.            | No              |
| `IsFraud`         | int64     | Binary indicator: 1 if the transaction is fraudulent, 0 otherwise. | Yes             |

## Pré-traitement des données - Nettoyage et formatage

### Subtask:
Gérer les doublons et formater les données si nécessaire.

**Reasoning**:
The first step in data preprocessing is to identify and handle duplicate rows to ensure data integrity. I will check for and remove duplicate rows from the DataFrame `df`.
"""

initial_rows = df.shape[0]
df.drop_duplicates(inplace=True)
duplicate_rows_removed = initial_rows - df.shape[0]
print(f"Number of duplicate rows removed: {duplicate_rows_removed}")

"""**Reasoning**:
The next instruction in the subtask is to convert the `TransactionDate` column to a datetime format to enable time-based analysis and operations.


"""

df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])
print("TransactionDate column converted to datetime format.")

"""## Pré-traitement des données - Imputation des valeurs manquantes

### Subtask:
Implémenter des stratégies avancées pour imputer les valeurs manquantes.

**Reasoning**:
The first step in implementing imputation strategies is to identify if there are any missing values in the DataFrame `df`. I will use `df.isnull().sum()` to check for missing values across all columns.
"""

missing_values = df.isnull().sum()
print("Missing values per column:")
print(missing_values)

if missing_values.sum() == 0:
    print("\nNo missing values found. No imputation is needed.")
else:
    print("\nMissing values detected. Imputation strategies may be required.")

"""## Pré-traitement des données - Encodage des variables catégorielles

### Subtask:
Appliquer des techniques d'encodage (One-Hot, Label Encoding, Target Encoding) aux variables catégorielles.

**Reasoning**:
The first step is to identify the categorical columns and apply one-hot encoding to 'TransactionType' and 'Location' to convert them into a numerical format suitable for machine learning models, and then display the head of the updated DataFrame.
"""

df = pd.get_dummies(df, columns=['TransactionType', 'Location'], drop_first=True)
print("Categorical columns 'TransactionType' and 'Location' have been one-hot encoded.")
df.head()

"""**Reasoning**:
To verify the changes after one-hot encoding, I will display the DataFrame's information using `df.info()` to confirm the new columns and their data types, as well as the overall structure of the DataFrame.


"""

df.info()

"""## Pré-traitement des données - Normalisation/Standardisation

### Subtask:
Normaliser ou standardiser les données numériques.

**Reasoning**:
First, I need to import the `StandardScaler` from `sklearn.preprocessing` to perform the standardization of numerical features.
"""

from sklearn.preprocessing import StandardScaler
print("StandardScaler imported successfully.")

"""**Reasoning**:
Now that `StandardScaler` is imported, I will select the numerical features ('Amount' and 'MerchantID') from the DataFrame, apply the scaler to standardize them, and then display the descriptive statistics of the scaled columns to confirm the transformation.


"""

numerical_features = ['Amount', 'MerchantID']

scaler = StandardScaler()
df[numerical_features] = scaler.fit_transform(df[numerical_features])

print("Numerical features 'Amount' and 'MerchantID' have been standardized.")
print("\nDescriptive statistics for scaled features:")
print(df[numerical_features].describe())

"""## Analyse Exploratoire des Données (EDA) - Visualisation des distributions

### Subtask:
Visualiser les distributions des variables numériques et catégorielles à l'aide d'histogrammes et de boxplots, et interpréter chaque graphique.

**Reasoning**:
The first step is to visualize the distribution of numerical features. I will create histograms for 'Amount' and 'MerchantID' to understand their central tendency, spread, and shape.
"""

import matplotlib.pyplot as plt
import seaborn as sns

numerical_features = ['Amount', 'MerchantID']

plt.figure(figsize=(12, 5))
for i, feature in enumerate(numerical_features):
    plt.subplot(1, 2, i + 1)
    sns.histplot(df[feature], kde=True)
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

print("Histograms for 'Amount' and 'MerchantID' have been displayed. The 'Amount' distribution appears to be relatively symmetrical and centered around zero after standardization, while 'MerchantID' also shows a bell-like shape but might have some variations due to its nature as an identifier that has been standardized.")

"""**Reasoning**:
The next step is to create boxplots for the numerical features ('Amount', 'MerchantID') to identify outliers and understand their quartiles and median, which complements the histograms by providing insights into data spread and potential anomalies.


"""

numerical_features = ['Amount', 'MerchantID']

plt.figure(figsize=(12, 5))
for i, feature in enumerate(numerical_features):
    plt.subplot(1, 2, i + 1)
    sns.boxplot(y=df[feature])
    plt.title(f'Boxplot of {feature}')
    plt.ylabel(feature)
plt.tight_layout()
plt.show()

print("Boxplots for 'Amount' and 'MerchantID' have been displayed. These plots help visualize the distribution, median, quartiles, and potential outliers for each feature. The 'Amount' boxplot appears symmetric around its median, with few visible outliers. The 'MerchantID' boxplot also shows a relatively symmetric distribution after standardization, with some outliers indicated by points beyond the whiskers.")

"""**Reasoning**:
The final step for visualizing distributions is to create count plots for the one-hot encoded categorical features and the target variable 'IsFraud' to understand the frequency of each category and identify any class imbalances, especially for the target variable.


"""

categorical_cols = [col for col in df.columns if col.startswith('TransactionType_') or col.startswith('Location_')] + ['IsFraud']

plt.figure(figsize=(15, 10))
for i, feature in enumerate(categorical_cols):
    plt.subplot(3, 4, i + 1) # Adjust subplot grid based on number of categorical features
    sns.countplot(data=df, x=feature)
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Count')
    plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

print("Count plots for one-hot encoded categorical features and 'IsFraud' have been displayed. These plots reveal the frequency of each category and highlight potential class imbalances, particularly for the 'IsFraud' target variable, which is crucial for fraud detection tasks.")

"""## Analyse Exploratoire des Données (EDA) - Analyse des corrélations

### Subtask:
Analyser les corrélations entre les variables, notamment avec la variable cible, en utilisant une heatmap, et interpréter les résultats.

**Reasoning**:
First, I need to calculate the correlation matrix for all numerical and boolean columns in the DataFrame `df`. This matrix will serve as the basis for visualizing the correlations.
"""

correlation_matrix = df.corr(numeric_only=True)
print("Correlation matrix calculated successfully.")
# Display the top 5 rows of the correlation matrix to verify
print(correlation_matrix.head())

"""**Reasoning**:
Now that the correlation matrix is calculated, I will create a heatmap to visualize these correlations, making sure it's appropriately sized and includes annotations for readability.


"""

plt.figure(figsize=(14, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix of Features')
plt.show()

print("Heatmap of the correlation matrix has been displayed. This visualization helps in understanding the linear relationships between all numerical features and the target variable 'IsFraud'. We can observe the strength and direction of correlations, which is crucial for feature selection and model building. Pay particular attention to features highly correlated with 'IsFraud' and any strong correlations between independent variables that might indicate multicollinearity.")

"""## Analyse Exploratoire des Données (EDA) - Feature Engineering

### Subtask:
Créer de nouvelles variables pertinentes à partir des features existantes pour améliorer la performance du modèle.

**Reasoning**:
The first step in feature engineering from the `TransactionDate` column is to extract the hour of the day. This will create a new feature representing the time of day the transaction occurred.
"""

df['TransactionHour'] = df['TransactionDate'].dt.hour
print("Extracted 'TransactionHour' from 'TransactionDate'.")

"""**Reasoning**:
Continuing with feature engineering, I will extract the day of the week and the month from the `TransactionDate` column to create new temporal features, then display the first few rows of the DataFrame to verify these additions.


"""

df['TransactionDayOfWeek'] = df['TransactionDate'].dt.dayofweek
df['TransactionMonth'] = df['TransactionDate'].dt.month
print("Extracted 'TransactionDayOfWeek' and 'TransactionMonth' from 'TransactionDate'.")
print("\nFirst 5 rows of DataFrame with new features:")
df.head()

"""**Reasoning**:
The final step in feature engineering for this subtask is to verify the newly created columns and their data types. I will use `df.info()` to display this information, ensuring that `TransactionHour`, `TransactionDayOfWeek`, and `TransactionMonth` have been correctly added and are of appropriate types.


"""

df.info()

"""## Modélisation Machine Learning - Sélection et comparaison d'algorithmes

### Subtask:
Tester et comparer au moins trois algorithmes de Machine Learning différents adaptés à la problématique définie.

**Reasoning**:
I will first import `train_test_split`, then define the features (X) by dropping 'TransactionID', 'TransactionDate', and 'IsFraud' columns, define the target variable (y) as 'IsFraud', and finally split the data into training and testing sets.
"""

from sklearn.model_selection import train_test_split

# Define features (X) and target (y)
X = df.drop(columns=['TransactionID', 'TransactionDate', 'IsFraud'])
y = df['IsFraud']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"y_test shape: {y_test.shape}")
print("Data split into training and testing sets successfully.")

"""**Reasoning**:
I will import three common classification algorithms: Logistic Regression, Decision Tree Classifier, and Random Forest Classifier, along with key evaluation metrics (accuracy, precision, recall, f1-score, roc_auc_score) to prepare for training and comparing them.


"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

print("Classification models and evaluation metrics imported successfully.")

"""**Reasoning**:
Now that the data is split and libraries are imported, I will train a Logistic Regression model, make predictions on the test set, and evaluate its performance using accuracy, precision, recall, f1-score, and ROC AUC score.


"""

model_lr = LogisticRegression(random_state=42, solver='liblinear')
model_lr.fit(X_train, y_train)

y_pred_lr = model_lr.predict(X_test)
y_proba_lr = model_lr.predict_proba(X_test)[:, 1]

print("Logistic Regression Model Evaluation:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_lr):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_lr):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_lr):.4f}")
print(f"ROC AUC Score: {roc_auc_score(y_test, y_proba_lr):.4f}")

"""**Reasoning**:
Following the evaluation of the Logistic Regression model, I will now train a Decision Tree Classifier, make predictions, and evaluate its performance using the same set of metrics to compare its effectiveness.


"""

model_dt = DecisionTreeClassifier(random_state=42)
model_dt.fit(X_train, y_train)

y_pred_dt = model_dt.predict(X_test)
y_proba_dt = model_dt.predict_proba(X_test)[:, 1]

print("Decision Tree Classifier Model Evaluation:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_dt):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_dt):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_dt):.4f}")
print(f"ROC AUC Score: {roc_auc_score(y_test, y_proba_dt):.4f}")

"""**Reasoning**:
After evaluating the Logistic Regression and Decision Tree models, I will now train a Random Forest Classifier, make predictions, and evaluate its performance using the same set of metrics to complete the comparison of the three algorithms.


"""

model_rf = RandomForestClassifier(random_state=42)
model_rf.fit(X_train, y_train)

y_pred_rf = model_rf.predict(X_test)
y_proba_rf = model_rf.predict_proba(X_test)[:, 1]

print("Random Forest Classifier Model Evaluation:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_rf):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_rf):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_rf):.4f}")
print(f"ROC AUC Score: {roc_auc_score(y_test, y_proba_rf):.4f}")

"""## Modélisation Machine Learning - Stratégie de validation

### Subtask:
Mettre en place une stratégie de validation rigoureuse, telle que la Cross-Validation, pour évaluer la robustesse des modèles.

**Reasoning**:
The first step in setting up a rigorous validation strategy is to import `StratifiedKFold` from `sklearn.model_selection` to handle potential class imbalance during cross-validation.
"""

from sklearn.model_selection import StratifiedKFold, cross_val_score
print("StratifiedKFold and cross_val_score imported successfully.")

"""**Reasoning**:
Now that the necessary cross-validation tools are imported, I will define a StratifiedKFold strategy and then apply it to each of the three trained models (Logistic Regression, Decision Tree, and Random Forest) to evaluate their performance using 'roc_auc' as the scoring metric and print the mean and standard deviation of the cross-validation scores.


"""

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

models = {
    "Logistic Regression": model_lr,
    "Decision Tree": model_dt,
    "Random Forest": model_rf
}

for name, model in models.items():
    # Using 'roc_auc' as the scoring metric for evaluation
    scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)
    print(f"{name} Cross-Validation ROC AUC: Mean = {scores.mean():.4f}, Std = {scores.std():.4f}")

"""## Modélisation Machine Learning - Optimisation des hyperparamètres

### Subtask:
Optimiser les hyperparamètres des modèles sélectionnés en utilisant des techniques comme GridSearchCV ou RandomizedSearchCV.

**Reasoning**:
The first step is to import `GridSearchCV` to enable hyperparameter optimization. Then, I will define a parameter grid for Logistic Regression, initialize `GridSearchCV` with `class_weight='balanced'` to address class imbalance, fit it to the training data, and finally print the best parameters and update the `model_lr`.
"""

from sklearn.model_selection import GridSearchCV

# Define parameter grid for Logistic Regression
param_grid_lr = {
    'C': [0.01, 0.1, 1, 10, 100],
    'solver': ['liblinear', 'saga'],
    'class_weight': ['balanced'] # Add class_weight to handle imbalance
}

# Initialize GridSearchCV for Logistic Regression
grid_search_lr = GridSearchCV(estimator=model_lr, param_grid=param_grid_lr, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)

# Fit GridSearchCV to the training data
print("Starting GridSearchCV for Logistic Regression...")
grid_search_lr.fit(X_train, y_train)
print("GridSearchCV for Logistic Regression completed.")

# Print best parameters and score for Logistic Regression
print(f"\nBest parameters for Logistic Regression: {grid_search_lr.best_params_}")
print(f"Best ROC AUC score for Logistic Regression: {grid_search_lr.best_score_:.4f}")

# Update model_lr with the best estimator
model_lr = grid_search_lr.best_estimator_
print("Logistic Regression model updated with best estimator.")

"""**Reasoning**:
Now, I will define a parameter grid for the `RandomForestClassifier` model, initialize `GridSearchCV` with `class_weight='balanced'` to address class imbalance, fit it to the training data, and then print the best parameters and update the `model_rf`.


"""

param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'class_weight': ['balanced']
}

# Initialize GridSearchCV for Random Forest
grid_search_rf = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)

# Fit GridSearchCV to the training data
print("Starting GridSearchCV for Random Forest...")
grid_search_rf.fit(X_train, y_train)
print("GridSearchCV for Random Forest completed.")

# Print best parameters and score for Random Forest
print(f"\nBest parameters for Random Forest: {grid_search_rf.best_params_}")
print(f"Best ROC AUC score for Random Forest: {grid_search_rf.best_score_:.4f}")

# Update model_rf with the best estimator
model_rf = grid_search_rf.best_estimator_
print("Random Forest model updated with best estimator.")

"""## Modélisation Machine Learning - Évaluation et interprétation des résultats

### Subtask:
Évaluer les performances des modèles optimisés à l'aide de métriques appropriées et interpréter les résultats.

## Summary:

### Data Analysis Key Findings

*   **Problem Definition:** The task was defined as a binary classification problem to predict credit card fraud (target variable `IsFraud`).
*   **Data Overview:** The dataset initially contained 100,000 rows and 7 columns. No duplicate rows were found, and no missing values were present in any columns.
*   **Data Preprocessing:**
    *   The `TransactionDate` column was successfully converted to datetime format.
    *   Categorical features (`TransactionType`, `Location`) were one-hot encoded, resulting in 10 new boolean columns and removal of original columns.
    *   Numerical features (`Amount`, `MerchantID`) were standardized, leading to means approximately 0 and standard deviations approximately 1.
*   **Feature Engineering:** Three new temporal features (`TransactionHour`, `TransactionDayOfWeek`, `TransactionMonth`) were successfully extracted from `TransactionDate`.
*   **Exploratory Data Analysis (EDA):**
    *   Histograms and boxplots showed that standardized `Amount` and `MerchantID` distributions were relatively symmetrical.
    *   Count plots highlighted a significant **class imbalance** in the `IsFraud` target variable, where fraudulent transactions (class 1) were a very small minority.
    *   The correlation analysis revealed very low linear correlations between `IsFraud` and all other features, with values generally ranging from -0.006 to 0.005.
*   **Model Performance (Initial Comparison):**
    *   Three classification algorithms (Logistic Regression, Decision Tree, Random Forest) were tested.
    *   All models achieved high accuracy (around 0.9895) but completely failed to detect fraudulent transactions, showing 0.0000 for precision, recall, and F1-score for the fraud class.
    *   Their initial ROC AUC scores were barely above 0.5 (e.g., Logistic Regression: 0.5083, Random Forest: 0.4956), indicating performance no better than random guessing.
*   **Cross-Validation Results:** Stratified 5-fold cross-validation confirmed the poor performance across all models, with mean ROC AUC scores remaining close to 0.5 (Logistic Regression: 0.4921, Decision Tree: 0.4982, Random Forest: 0.5033).
*   **Hyperparameter Optimization (with `class_weight='balanced'`):**
    *   Using `GridSearchCV` and `class_weight='balanced'` led to slight improvements in ROC AUC scores.
    *   Optimized Logistic Regression achieved a best ROC AUC of 0.5160.
    *   Optimized Random Forest Classifier achieved a best ROC AUC of 0.5313.
    *   Despite optimization and addressing class imbalance, the ROC AUC scores remained very low, indicating the models still struggle to effectively distinguish fraudulent transactions.

### Insights or Next Steps

*   **Address Severe Class Imbalance:** Given the extremely poor performance of all models in detecting fraud, even after applying `class_weight='balanced'` and optimizing hyperparameters, it is critical to implement more advanced techniques to handle the severe class imbalance. This could include oversampling minority class examples (e.g., SMOTE, ADASYN) or undersampling majority class examples.
*   **Explore More Advanced Models or Feature Interactions:** The current features and linear/tree-based models do not capture the underlying patterns for fraud detection effectively. Investigating more complex models (e.g., Gradient Boosting Machines like XGBoost/LightGBM, neural networks) or focusing on creating more sophisticated interaction features that might better represent fraudulent behavior is recommended.
"""