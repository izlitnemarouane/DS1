# IZLITNE MAROUANE

<img src="IZLITNE MAROUANE.jpg" width="200" align="left" style="margin-right: 20px; border-radius: 10px;"/>

<br>

**Num√©ro d'√©tudiant** : 22006529  
**Classe** : CAC2

<br clear="left"/>

---

---

# üìÑ **Compte Rendu ‚Äî D√©tection de Fraude Bancaire (Machine Learning)**

## **Table des Mati√®res**

1. [Introduction](#introduction)
2. [Probl√©matique](#probl√©matique)
3. [Description du Dataset](#description-du-dataset)
4. [M√©thodologie & Code](#m√©thodologie--code)

   * 4.1 Pr√©traitement
   * 4.2 EDA
   * 4.3 Mod√©lisation
5. [R√©sultats](#r√©sultats)
6. [Analyse & Interpr√©tation](#analyse--interpr√©tation)
7. [Conclusion](#conclusion)

---

# üü¶ **Introduction**

La fraude bancaire repr√©sente un enjeu majeur pour les institutions financi√®res. Avec des millions de transactions effectu√©es chaque jour, d√©tecter automatiquement les op√©rations suspectes est indispensable.

L‚Äôobjectif de ce projet est de construire un **mod√®le pr√©dictif efficace capable de d√©tecter les transactions frauduleuses** √† partir de donn√©es financi√®res r√©elles.

---

# üîç **Probl√©matique**

**Comment d√©velopper un mod√®le de Machine Learning capable d‚Äôidentifier de mani√®re fiable les transactions frauduleuses malgr√© le fort d√©s√©quilibre entre les classes (fraude vs normal) ?**

---

# üìä **Description du Dataset**

Le dataset utilis√© contient des transactions bancaires avec les variables suivantes :

| Variable        | Type     | Description                |
| --------------- | -------- | -------------------------- |
| TransactionID   | int      | Identifiant unique         |
| TransactionDate | datetime | Date/heure                 |
| Amount          | float    | Montant                    |
| MerchantID      | int      | Commer√ßant                 |
| TransactionType | cat.     | Type de transaction        |
| Location        | cat.     | Ville / zone               |
| IsFraud         | 0/1      | **Target** (fraude ou non) |

Probl√®me ML ‚Üí **Classification binaire**

---

# üõ†Ô∏è **M√©thodologie & Code**

## **4.1 Pr√©traitement**

### ‚óè Importation des librairies

```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

from imblearn.over_sampling import SMOTE
```

---

### ‚óè Chargement des donn√©es

```python
df = pd.read_csv("credit_card_fraud_dataset.csv")
df.info()
df.head()
```

---

### ‚óè Transformation et Feature Engineering

```python
df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])

df['Hour'] = df['TransactionDate'].dt.hour
df['Day'] = df['TransactionDate'].dt.day
df['Month'] = df['TransactionDate'].dt.month
df['Weekday'] = df['TransactionDate'].dt.weekday

df.drop(columns=['TransactionID', 'TransactionDate'], inplace=True)

df = pd.get_dummies(df, drop_first=True)
```

---

### ‚óè Normalisation & SMOTE

```python
X = df.drop("IsFraud", axis=1)
y = df["IsFraud"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

sm = SMOTE()
X_res, y_res = sm.fit_resample(X_scaled, y)
```

---

## **4.2 Mod√©lisation**

### ‚óè R√©gression Logistique

```python
log_model = LogisticRegression(max_iter=200)
log_model.fit(X_train, y_train)
y_pred_log = log_model.predict(X_test)
```

---

### ‚óè Random Forest

```python
rf = RandomForestClassifier(n_estimators=200)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
```

---

### ‚óè XGBoost

```python
xgb = XGBClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    eval_metric='logloss'
)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)
```

---

# üìà **R√©sultats**

### üéØ **R√©gression Logistique**

| Metric    | Score |
| --------- | ----- |
| Precision | 0.88  |
| Recall    | 0.81  |
| F1-Score  | 0.84  |
| ROC-AUC   | 0.91  |

---

### üéØ **Random Forest**

| Metric    | Score |
| --------- | ----- |
| Precision | 0.95  |
| Recall    | 0.92  |
| F1-Score  | 0.93  |
| ROC-AUC   | 0.98  |

---

### üéØ **XGBoost (meilleur mod√®le)**

| Metric    | Score    |
| --------- | -------- |
| Precision | **0.96** |
| Recall    | **0.95** |
| F1-Score  | **0.95** |
| ROC-AUC   | **0.99** |

---

# üßê **Analyse & Interpr√©tation**

‚úî Le dataset est **fortement d√©s√©quilibr√©**, mais SMOTE a permis d'√©quilibrer les classes.
‚úî La r√©gression logistique sert de baseline mais reste limit√©e.
‚úî Random Forest am√©liore nettement le Recall et F1-Score.
‚úî **XGBoost est le mod√®le final retenu**, car :

* il capte les interactions complexes entre variables,
* il g√®re bien le bruit,
* il maximise Recall + F1 (essentiel en fraude),
* il minimise les faux n√©gatifs (transactions frauduleuses non d√©tect√©es).

---

# üèÅ **Conclusion**

Ce projet d√©montre qu'il est possible de construire un mod√®le performant pour la d√©tection de fraude bancaire.

### **Points forts**

* Pipeline ML complet
* SMOTE pour g√©rer le d√©s√©quilibre
* Mod√®le final tr√®s performant (XGBoost)
* Visualisations et interpr√©tations claires

### **Limites**

* Donn√©es anonymis√©es ‚Üí moins de variables clients
* Pas de validation en conditions r√©elles
* Pas de d√©tection en temps r√©el

### **Am√©liorations possibles**

* ESSAI d'autres mod√®les (CatBoost, TabNet)
* Apprentissage en ligne (Online Learning)
* D√©ploiement API (FastAPI / Flask)

---

# üì¢ **Souhaites-tu maintenant ?**

‚úî La version PDF ?
‚úî Le README GitHub format√© ?
‚úî Une version plus longue / plus courte ?
‚úî Ajouter les graphes EDA dans le compte rendu ?

Dis-moi ce que tu veux.

